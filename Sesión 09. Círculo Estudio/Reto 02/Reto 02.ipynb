{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 03\n",
    "Bienvenido al siguiente reto del día de hoy. Aprenderás a modelar y generar una red neuronal distinta al enfoque clásico de sesiones anteriores y a la convulsiva que viste en el Reto 01 de la presente sesión. Hoy aprenderás a modelar una red neuronal recurrente o recurrent neuronal recurrent (RNN), la cual usa i hasta k rezagos (mira el pasado de los datos) para generar una proyección, la cual es perfecta para la modelación de datos estructurados en formato de serie temporal.\n",
    "\n",
    "En este reto en particular, usted deberá generar y modelar una RNN para proyectar el precio de las acciones de google que datan desde 2012 hasta 2016 ¡Éxito!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías a usar\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1\n",
    "Cargue \"Google_Stock_Price_Train.csv\" con pandas y almacenelo en una variable que se va a llamar dataset_train. Acto seguido use pandas.loc para acceder a todos los valores de \"open\", y los almacernará en una variable que se va a llamar train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 02\n",
    "Ahora, usted va a generar una escala nueva que irá desde 0 a 1, pero no se preocupe, es muy sencillo, ya que se apoyará de las siguiente librería:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siga estos pasos:\n",
    "- Defina una variable llamada scaler que adentro tendra almacenada la función MinMaxScaler()\n",
    "- Acto seguido, defina una llamada trained_scaled que tendrá almacenado scaler.fit_transform, y dentro de esa función estará la variable ya definida 'train'\n",
    "- Para verificar que todo esté funcionando correctamente, generé un print de la nueva variable 'train_scaled'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 03\n",
    "Genere una gráfica de la serie temporal de train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 04\n",
    "Ahora su deber es generar un loop de procesamiento del training dataset, con las variables inicializadas que puede ver en el pedazo de código debajo. El loop debe desarrollarse de la siguiente manera:\n",
    "- el loop es de tipo for. La idea es que para i en el range desde timestamps hasta 1258...\n",
    "    - se le haga un append a X_train de tal manera que el valor a agregar lo obtenga de train_scaled, desde i-timeseps hasta i, haciendolo por filas\n",
    "    - Lo mismo para y_train, salvo que el append será mucho más sencillo pues solo agregaremos i, igualmente por filas\n",
    "    \n",
    "- Tras acabar ese loop, redefinirás las variables X_train y y_ train a arrays de numpy (solo esa conversión)\n",
    "- Despues de eso, comprueba el shape de tus variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 05\n",
    "Ahora vas a comenzar a entrenar tu red neuronal recurrente. Usa las siguientes librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigue a detalle los siguientes pasos para generar tu red neuronal. Si tienes una duda, no dudes en consultar al profesor:\n",
    "- Inicializa una variable llamada regressor con Sequential() adentro de ella\n",
    "- acto seguido, usa la siguiente parte de código:\n",
    "regressor.add(SimpleRNN(units = 45,activation='tanh',recurrent_dropout=True, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.15))\n",
    "\n",
    "- El segundo layer será identico pero sin el argumento input_shape = (X_train.shape[1], 1)\n",
    "- El tercer layer será idéntico al pasado\n",
    "- El cuarto layer sigue igual pero le quitarás los argumentos activation='tanh',recurrent_dropout=True,return_sequences = True\n",
    "- El quinto layer es idéntico al cuarto pero con units = 1 y ahora sin regressor.add(Dropout(0.15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 06\n",
    "Ahora deberá compilar su red almacenada en la variable 'regressor'. Use el optimizador de adam pero ahora en la función de perdida (loss), es decir, el costo de optmización entre lo que se proyecta y lo que se observa, será la función del error cuadratico medio del modelo clásico de minímos cuadrados ordinarios (mean_squared_error).\n",
    "\n",
    "Acto seguido, enbone sus variables X_train y y_train. Le recomiendo usar 30 epochs (iteraciones de entrenamiento para todo el dataset) con un batch size de 32 (número de muestras para la actualización en el cálculo del descenso en gradiente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 07\n",
    "Cargue con pandas el archivo 'Google_Stock_Price_Test' y almacenelo en una variable llamada 'dataset_test'.\n",
    "Acto seguido, defina na variable llamada real_stock_price que solo tendrá los valores de la variable 'open' (los valores realmente observados de la serie). Use .values y la función pandas.loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 08. Combinación de testing y training datasets para probar el modelo\n",
    "Ahora siga los siguientes pasos:\n",
    "- defina una variable llamada dataset_total que debe contener una concatenación entre los valores de 'open' de dataset_train y los de dataset_test\n",
    "- defina una variable llamada inputs, que tendrá almacenado un sclicing de numpy de la variable dataset_total (dataset_train[]) de la operación que resulte de len(dataset_train)-len(dataset_test)- timesteps:. Todo ello, deberá transponerlo\n",
    "- redefina inputs para aplicar un scaler.transform a la misma variable inputs\n",
    "- verifique que haya tenido éxito con un inputs.shape, el cual deberá ser igual a (90, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 09.\n",
    "Genere una aleatorización de los valores de X_test. Siga las siguientes instrucciones:\n",
    "- defuna variable vacia X_test = []\n",
    "- Va a ir llenando la variable antes definida, deberá generar un for i in range de timesteps hasta 70 (observaciones totales que deseamos)\n",
    "    - Adentro del loop se generará un append a X_test de la operación inputs[i-timesteps:i, 0]\n",
    "    \n",
    "Después, convierte a array de numpy a X_test.\n",
    "\n",
    "Acto seguido, redefine X_test aplica un reshape con lo siguiente dentro: X_test, (X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "Ahora define una variable llamada predicted_stock_price que tendrá  dentro regressor.predict(X_test).\n",
    "\n",
    "Por último, redefine predicted_stock_price, con un scaler.inverse_transform(predicted_stock_price) dentro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 10\n",
    "Generé una gráfica de la serie de los valores observados contra los proyectados con la red neuronal que usted creó"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
